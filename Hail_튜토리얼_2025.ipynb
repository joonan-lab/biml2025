{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc632822-976b-4c2c-9502-ae6d93b5216b"
      },
      "source": [
        "# Hail을 이용한 전장유전체 분석 기초 실습\n",
        "\n",
        "고려대학교 인간유전체 연구실 (안준용, 이혜지)\n",
        "\n",
        "Update: 2025/1/24\n",
        "\n",
        "Hail을 이용한 전장유전체 데이터 분석 튜토리얼에 오신 여러분을 환영합니다.\n",
        "\n",
        "본 튜토리얼을 구동하기 위해선, 오른쪽 상단에 있는 Connect 버튼을 누르면 자동으로 구글 코랩이 연결됩니다. 현재 튜토리얼은 구글 코랩에서 사용할 수 있도록 작성되었습니다. 튜토리얼에 사용할 데이터는 다음 링크 - [데이터](https://www.dropbox.com/s/9kquuf894toh98j/data.tar.gz?dl=0)에서 다운 받을 수 있습니다. 다운로드 받은 데이터는 수강생 여러분이 사용하는 구글 드라이브에 업로드하여 주시길 바랍니다. 튜토리얼의 데이터는 [1000 Genome Project의 high coverage depth WGS](https://www.internationalgenome.org/data/) VCF 중 염색체 22번 일부를 임의로 추출하였습니다.\n",
        "\n",
        "튜토리얼은 자유롭게 재배포 가능합니다. 다만 자료는 제가 공개된 데이터를 임의로 변경하였기 때문에, 꼭 출처를 명시할 필요가 있습니다. 해당 튜토리얼에 대한 피드백은 joonan30@korea.ac.kr 에게 메일을 주세요. 질문은 워크샵 수업시간 외에 따로 받지 않습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4800049d"
      },
      "source": [
        "## Hail 설정 및 데이터 불러들이기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3338b07e"
      },
      "source": [
        "Hail은 Apache Spark에서 구동되므로, java JRE 버젼 8이나 11이 요구됩니다. 설치 방법은 Hail.is에 나온대로 `pip` 를 이용하여 설치하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhflaONZlYis",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Hail 및 필요한 라이브러리 설치하세요. 설치 과정에서 재부팅 (restart) 버튼이 나올수도 있습니다.\n",
        "!pip install hail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1zAZUfanF7m"
      },
      "outputs": [],
      "source": [
        "# 왼쪽 패널에서 구글 드라이브 마운트를 선택하여 본인 구글 드라이브와 데이터를 연결해주세요. 연결 후에는 drive 라는 폴더가 나올 것입니다\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fZDdudAnPWs"
      },
      "outputs": [],
      "source": [
        "# 연결 후에, 필요한 데이터를 현재 작업 디스크에 압축을 풀어주도록 하겠습니다.\n",
        "!tar -xvzf drive/MyDrive/Hail_tutorial/data.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f078199b-b52d-4720-9f18-97b9ec603396"
      },
      "outputs": [],
      "source": [
        "from bokeh.io import show, output_notebook\n",
        "from bokeh.layouts import gridplot\n",
        "import pandas as pd\n",
        "output_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf6e7364-d270-4fa2-bb0a-1a326dba4732"
      },
      "outputs": [],
      "source": [
        "import hail as hl # Hail 라이브러리 로드\n",
        "hl.init() # Hail 설정이 잘 되었는지 확인합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d12f147-5600-47e3-bcb7-13d5bb7b3ea9"
      },
      "source": [
        "### VCF 데이터 불러들이기\n",
        "\n",
        "VCF 파일을 로드하기 위해 사용되는 함수는 `hl.import_vcf()` 입니다. 이 함수는 VCF 포맷의 데이터를 matrix table 형태로 읽어들이게 됩니다. 우리가 사용하는 데이터는 hg38 버전에서 mapping 되어 있으므로, reference genome 옵션에는 `GRCh38`을 입력해봅시다.\n",
        "이 외에도 txt, bed, bgen 등의 포맷을 불러들일 수 있는 다양한 함수가 존재합니다. 다음 링크의 hail document를 참고해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ace29e4f-a8c2-4d5a-92bc-8125c39c4312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f922a736-4526-4536-efdf-b9908a7a022e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-28 07:33:59.160 Hail: INFO: scanning VCF for sortedness...\n",
            "2025-01-28 07:34:15.055 Hail: INFO: Coerced sorted VCF - no additional import work to do\n",
            "2025-01-28 07:35:49.601 Hail: INFO: wrote matrix table with 16515 rows and 3202 columns in 2 partitions to data/out_test_chr22.mt\n"
          ]
        }
      ],
      "source": [
        "mt = hl.import_vcf('data/out.test.chr22.vcf.bgz',\n",
        "                   reference_genome = 'GRCh38',\n",
        "                   array_elements_required=False)\n",
        "mt = mt.checkpoint('data/out_test_chr22.mt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e0f8264-9b3b-407d-82bc-2b59879686f1"
      },
      "source": [
        "분석에 들어가기에 앞서, 데이터가 실제로 어떻게 구성되어 있는지 살펴보아야 합니다. 데이터의 전체적인 구조를 살펴보고 싶을 때는 `describe()`를 사용해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d69518ce-7d08-4cb6-8ebe-1923bc882673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5eda6d5-c94b-4ead-9f6c-dbacebf904cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Global fields:\n",
            "    None\n",
            "----------------------------------------\n",
            "Column fields:\n",
            "    's': str\n",
            "----------------------------------------\n",
            "Row fields:\n",
            "    'locus': locus<GRCh38>\n",
            "    'alleles': array<str>\n",
            "    'rsid': str\n",
            "    'qual': float64\n",
            "    'filters': set<str>\n",
            "    'info': struct {\n",
            "        AC: array<int32>, \n",
            "        AF: array<float64>, \n",
            "        AN: int32, \n",
            "        BaseQRankSum: float64, \n",
            "        ClippingRankSum: float64, \n",
            "        DP: int32, \n",
            "        DS: bool, \n",
            "        END: int32, \n",
            "        FS: float64, \n",
            "        HaplotypeScore: float64, \n",
            "        InbreedingCoeff: float64, \n",
            "        MLEAC: array<int32>, \n",
            "        MLEAF: array<float64>, \n",
            "        MQ: float64, \n",
            "        MQ0: int32, \n",
            "        MQRankSum: float64, \n",
            "        NEGATIVE_TRAIN_SITE: bool, \n",
            "        POSITIVE_TRAIN_SITE: bool, \n",
            "        QD: float64, \n",
            "        RAW_MQ: float64, \n",
            "        ReadPosRankSum: float64, \n",
            "        SOR: float64, \n",
            "        VQSLOD: float64, \n",
            "        VariantType: str, \n",
            "        culprit: str, \n",
            "        AN_EUR: int32, \n",
            "        AN_EAS: int32, \n",
            "        AN_AMR: int32, \n",
            "        AN_SAS: int32, \n",
            "        AN_AFR: int32, \n",
            "        AC_EUR: array<int32>, \n",
            "        AC_EAS: array<int32>, \n",
            "        AC_AMR: array<int32>, \n",
            "        AC_SAS: array<int32>, \n",
            "        AC_AFR: array<int32>, \n",
            "        AC_Hom_EUR: array<int32>, \n",
            "        AC_Hom_EAS: array<int32>, \n",
            "        AC_Hom_AMR: array<int32>, \n",
            "        AC_Hom_SAS: array<int32>, \n",
            "        AC_Hom_AFR: array<int32>, \n",
            "        AC_Hom: array<int32>, \n",
            "        AC_Het_EUR: array<int32>, \n",
            "        AC_Het_EAS: array<int32>, \n",
            "        AC_Het_AMR: array<int32>, \n",
            "        AC_Het_SAS: array<int32>, \n",
            "        AC_Het_AFR: array<int32>, \n",
            "        AC_Het: array<int32>, \n",
            "        AF_EUR: array<float64>, \n",
            "        AF_EAS: array<float64>, \n",
            "        AF_AMR: array<float64>, \n",
            "        AF_SAS: array<float64>, \n",
            "        AF_AFR: array<float64>, \n",
            "        HWE_EUR: array<float64>, \n",
            "        HWE_EAS: array<float64>, \n",
            "        HWE_AMR: array<float64>, \n",
            "        HWE_SAS: array<float64>, \n",
            "        HWE_AFR: array<float64>, \n",
            "        HWE: array<float64>, \n",
            "        ExcHet_EUR: array<float64>, \n",
            "        ExcHet_EAS: array<float64>, \n",
            "        ExcHet_AMR: array<float64>, \n",
            "        ExcHet_SAS: array<float64>, \n",
            "        ExcHet_AFR: array<float64>, \n",
            "        ExcHet: array<float64>, \n",
            "        ME: array<float64>, \n",
            "        AN_EUR_unrel: int32, \n",
            "        AN_EAS_unrel: int32, \n",
            "        AN_AMR_unrel: int32, \n",
            "        AN_SAS_unrel: int32, \n",
            "        AN_AFR_unrel: int32, \n",
            "        AC_EUR_unrel: array<int32>, \n",
            "        AC_EAS_unrel: array<int32>, \n",
            "        AC_AMR_unrel: array<int32>, \n",
            "        AC_SAS_unrel: array<int32>, \n",
            "        AC_AFR_unrel: array<int32>, \n",
            "        AC_Hom_EUR_unrel: array<int32>, \n",
            "        AC_Hom_EAS_unrel: array<int32>, \n",
            "        AC_Hom_AMR_unrel: array<int32>, \n",
            "        AC_Hom_SAS_unrel: array<int32>, \n",
            "        AC_Hom_AFR_unrel: array<int32>, \n",
            "        AC_Het_EUR_unrel: array<int32>, \n",
            "        AC_Het_EAS_unrel: array<int32>, \n",
            "        AC_Het_AMR_unrel: array<int32>, \n",
            "        AC_Het_SAS_unrel: array<int32>, \n",
            "        AC_Het_AFR_unrel: array<int32>, \n",
            "        AF_EUR_unrel: array<float64>, \n",
            "        AF_EAS_unrel: array<float64>, \n",
            "        AF_AMR_unrel: array<float64>, \n",
            "        AF_SAS_unrel: array<float64>, \n",
            "        AF_AFR_unrel: array<float64>, \n",
            "        HWE_EUR_unrel: array<float64>, \n",
            "        HWE_EAS_unrel: array<float64>, \n",
            "        HWE_AMR_unrel: array<float64>, \n",
            "        HWE_SAS_unrel: array<float64>, \n",
            "        HWE_AFR_unrel: array<float64>, \n",
            "        CSQ: array<str>\n",
            "    }\n",
            "----------------------------------------\n",
            "Entry fields:\n",
            "    'AB': float64\n",
            "    'AD': array<int32>\n",
            "    'DP': int32\n",
            "    'GQ': int32\n",
            "    'GT': call\n",
            "    'MIN_DP': int32\n",
            "    'MQ0': int32\n",
            "    'PGT': call\n",
            "    'PID': str\n",
            "    'PL': array<int32>\n",
            "    'RGQ': int32\n",
            "    'SB': array<int32>\n",
            "----------------------------------------\n",
            "Column key: ['s']\n",
            "Row key: ['locus', 'alleles']\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9909cb8a"
      },
      "source": [
        "\n",
        "#### Matrix Table의 구조\n",
        "\n",
        "Matrix table은 총 네 가지 필드로 구분됩니다. 우리의 데이터는 각 필드에 어떤 정보를 담고 있을까요? 이것을 이해하기 위해서는 VCF format에 대해 생각해봐야 합니다.\n",
        "\n",
        "VCF format은 총 8가지의 variant information (CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO), 그리고 genotype information (FORMAT, n*sample) 으로 이루어져 있습니다.\n",
        "\n",
        "![VCF와 Hail matrix table 개요](https://www.dropbox.com/s/kn0hm8oy7ucxqum/vcf_to_hail.png?raw=1)\n",
        "\n",
        "##### Row 필드\n",
        "\n",
        "Row 필드 8개의 variant information이 matrix table에 들어가게 됩니다. CHROM, POS 는 'locus'라는 변수로, REF, ALT는 'alleles'라는 변수로 치환되죠. 그리고 이 두 변수는 Row 필드의 key로 지정됩니다.\n",
        "\n",
        "##### Column 필드\n",
        "\n",
        "Column 필드는 각 샘플의 메타 정보를 담고 있습니다. VCF Header 중 sample name이 Column 필드로 들어가게 됩니다. 이것은 마찬가지로 Column 필드의 key로 지정됩니다.\n",
        "\n",
        "##### Entry 필드\n",
        "\n",
        "Entry 필드는 샘플별 genotype information를 의미합니다. VCF 파일에서의 FORMAT 데이터가 Entry 필드로 들어가는 것이죠.\n",
        "\n",
        "간단하게 말하면 Column 필드는 sample level information, Row 필드는 variant level information, Entry 필드는 genotype level information 라고 할 수 있습니다.\n",
        "\n",
        "이번엔 데이터가 어떻게 기록되어 있는지 눈으로 확인할 차례입니다. show() 를 사용하여 데이터의 각 필드를 도표 형태로 출력해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10e05274"
      },
      "outputs": [],
      "source": [
        "mt.cols().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56385ad8"
      },
      "outputs": [],
      "source": [
        "mt.rows().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ef35e6"
      },
      "outputs": [],
      "source": [
        "mt.entries().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ac55bfb"
      },
      "source": [
        "### 샘플 정보 불러들이기\n",
        "\n",
        "\n",
        "Column 필드는 sample level information, 즉 샘플 개개인의 메타 정보를 담고 있습니다. 하지만 VCF 파일에서 얻을 수 있는 샘플 정보는 이름밖에 없죠. 따라서 샘플의 Pedigree 정보를 알 수 있는 '.ped' 포맷의 파일을 불러들일 것입니다. Ped 파일을 불러들일 때는 `import_fam()`를 사용합니다. Ped file format은 Pedigree, Sex, Phenotype 정보를 담고 있습니다. 자세한 정보는 다음 [링크](https://gatk.broadinstitute.org/hc/en-us/articles/360035531972-PED-Pedigree-format)를 참고하세요. 이 가족 데이터를 이용해서 inherited variant (유전이 되는 유전 변이)와 germline de novo variant (부모의 생식세포에서 발생하여 자녀에게만 나타나는 변이)를 확인하려고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccea3f09-2b39-46b7-8d6d-d903eac96315"
      },
      "outputs": [],
      "source": [
        "fam = hl.import_fam('data/1kg_v3_20200731_complete_fam_633.ped')\n",
        "fam.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b54eb2a"
      },
      "source": [
        "이 외에도 샘플 정보를 추가하고 싶으면, 테이블 형태(txt, tsv 등) 파일을 불러들여 추가할 수 있습니다. 우리는 샘플이 자녀인지, 부모인지를 구분하기 위해 추가적인 정보를 하나 더 불러오도록 하겠습니다. `import_table()`는 txt, tsv 등의 파일을 hail table 형태로 읽어들입니다. 데이터 불러들일 때 'key' 옵션을 통해 특정 변수를 key로 지정할 수 있습니다. Hail 에서 VCF, bed, ped 등 고정된 형식의 데이터를 불러올 때는 자동적으로 key가 지정됩니다. 하지만 두 번째로 불러들인 txt 파일은 그렇지 않기 때문에 옵션을 통해 샘플 id를 key로 지정해줘야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b53e635b"
      },
      "outputs": [],
      "source": [
        "info = hl.import_table('data/1kg_v3_20200731_complete_fam_633.txt',\n",
        "                       key = 'Individual ID',\n",
        "                       types = {'height' : hl.tfloat, 'NVIQ' : hl.tfloat})\n",
        "info.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d885d4d"
      },
      "source": [
        "불러온 샘플 정보를 Column 필드에 annotate 할 차례입니다. `annotate_cols()` 함수를 사용해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "770bfc32-ee54-4447-9061-ee711b600442"
      },
      "outputs": [],
      "source": [
        "# Annotate sample & pedigree information to variants data\n",
        "mt = mt.annotate_cols(fam = fam[mt.s].fam_id,\n",
        "                     pat_id = fam[mt.s].pat_id,\n",
        "                     mat_id = fam[mt.s].mat_id,\n",
        "                     isFemale = fam[mt.s].is_female,\n",
        "                     phenotype = fam[mt.s].is_case,\n",
        "                     ROLE = info[mt.s].ROLE,\n",
        "                     population = info[mt.s].Population,\n",
        "                     height = info[mt.s].height,\n",
        "                     NVIQ = info[mt.s].NVIQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65a43078"
      },
      "outputs": [],
      "source": [
        "mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebe699b7"
      },
      "source": [
        "이번엔 샘플 정보에 따라 matrix table에 존재하는 샘플들을 추출해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb9e2b76"
      },
      "outputs": [],
      "source": [
        "print(\"Before filtering samples, (# of variants, # of samples) = \", mt.count())\n",
        "mt_chs = mt.filter_cols(mt.population=='CHS', keep=True) # filter out samples that are not in ped file\n",
        "print(\"After filtering samples, (# of variants, # of samples) = \", mt_chs.count())\n",
        "# mt.cols().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01343ff3"
      },
      "source": [
        "### Function annotation 을 추가하기\n",
        "\n",
        "전장유전체 분석에서 찾은 유전변이가 특정 기능을 담당하는 지역에서 발생할 수 있습니다. 전장유전체는 noncoding genome에서도 변이를 찾을 수 있기 때문에, 유전자 발현과정에서 전사조절인자가 붙는 지역을 지정하면, 그 지역에서 발생한 변이를 추출할 수 있습니다. 아래는 ENCODE 프로젝트에서 chip-seq을 통해 찾은 다양한 Cis-Regulatory Elements (CRE)가 붙는 유전체 지역에 대한 정보를 bed file 형태로 UCSC에서 다운로드 받았습니다 ([링크](https://genome.ucsc.edu/cgi-bin/hgTrackUi?hgsid=1259223423_dDFJRqzUKODz4m3GycQ5RA0apAYw&db=hg38&c=chr22&g=encodeCcreCombined)).\n",
        "\n",
        "```\n",
        "bigBedToBed http://hgdownload.soe.ucsc.edu/gbdb/hg38/encode3/ccre/encodeCcreCombined.bb -chrom=chr22 -start=0 -end=100000000 stdout | cut -f1-4 > ucsc.encode_cre.hg38.bed\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b971f2c"
      },
      "outputs": [],
      "source": [
        "tb_encode_cre = hl.import_bed('data/ucsc.encode_cre.hg38.bed', reference_genome='GRCh38')\n",
        "tb_encode_cre.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f944b9cb"
      },
      "source": [
        "## Hail 기본 문법을 이용한 데이터 둘러보기\n",
        "\n",
        "Hail 기본 문법에 익숙해지기 위해, 불러드린 자료들의 정보를 확인해봅시다.\n",
        "\n",
        "### 유전변이 정보 확인하기\n",
        "\n",
        "GATK 파이프라인에서 만들어진 VCF는 각 샘플의 variant와 genotype 정보를 갖고 있습니다. Variant는 특정 locus에서 염기서열이 어떻게 변화했는지에 대한 것이고, genotype은 allele에 대한 정보를 갖고 있습니다.\n",
        "\n",
        "또한, VCF에는 variant calling에 대한 품질지표(quality metrics)를 variant과 genotype에 대하여 제공합니다.\n",
        "\n",
        "1. Variant 수준의 품질 지표는 해당 VCF에 존재하는 샘플들에게 공통적으로 산출된 지표이고, locus 수준의 지표라고 할 수 있습니다. INFO 컬럼에 저장되어 있습니다.\n",
        "2. Genotype 수준의 품질 지표는 각 locus에서 발견된 variant에 대하여 샘플이 갖는 지표를 말합니다. 각 샘플 컬럼에 저장되어 있고, FORMAT 컬럼에 저장된 지표들을 따릅니다. 예를들어, FORMAT에 GT:AD:PL 순서로 나온다면, 샘플 컬럼에도 동일한 정보(0/1:30,30:100,0,1000)로 저장되어 있습니다.\n",
        "\n",
        "먼저 특정 locus에서 variant를 추출해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b94d6978"
      },
      "outputs": [],
      "source": [
        "locus = hl.locus(contig = \"chr22\", pos = 50197928, reference_genome = 'GRCh38')\n",
        "mt.filter_rows(mt.locus == locus).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62fdd4c7"
      },
      "source": [
        "자, 염색체 22번의 `50197928` 번째 위치에  나타난 변이를 보면 `[\"C\", \"T\"]`와 같은 list가 존재합니다. 처음의 `C`는 reference allele에 해당하고, `T`는 alternative allele에 해당합니다. 우리는 `T`를 `변이(variant)`라고 부릅니다.\n",
        "\n",
        "변이는 \"염기서열 상의 변화\"이고 현재 사용하는 VCF에 하나의 row에 기록됩니다.\n",
        "\n",
        "유전형(genotype)은 이 VCF에 포함된 샘플들에 개별적으로 기록됩니다. 유전형은 3가지 경우로 구분됩니다.\n",
        "\n",
        "\n",
        "이번에는 특정 지역에서 발생하는 variant를 추출해봅시다. 우리는 염색체 22q13.2에 위치한 MIOX 유전자에 발생한 변이들을 보고 싶습니다. 이 유전자는 Myo-Inositol을 대사하는 효소를 암호화하며, 신장과 관련된 대사 경로에서 중요한 역할을 합니다. 그러면 MIOX 위치(`chr22:50482037-50485195`)를 이용해서 변이를 추출해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58149cfb"
      },
      "outputs": [],
      "source": [
        "locus = hl.locus_interval(\"chr22\", 50482037, 50485195, reference_genome='GRCh38')\n",
        "hl.filter_intervals(mt, [locus]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf05a88a"
      },
      "source": [
        "일반적으로 인간 유전체의 유전변이는 2개의 allele로 구성된 3개의 유전형(genotype)을 갖습니다. 이것을 bi-allelic variant라고 부릅니다. 하나의 allele은 참조유전체(reference genome)과 동일한 것이므로 reference allele이라 부르고, 다른 하나는 변이에 의해 생기는 alternative allele (혹은 variant라고 allele)이라고 부릅니다.\n",
        "\n",
        "그러나 종종 예외도 존재합니다. 바로 multi-allelic variant 입니다. 위 테이블을 보시면, 두가지 이상의 allele이 나오는 경우가 있습니다. `50674782` 위치에서 발생한 변이를 보면, `[\"C\",\"A\",\"G\"]`이와 같이 3개의 allele이 존재합니다. 우리는 이걸 `multi-allelic variant`라고 부릅니다. 같은 locus에 두개 이상의 alternative allele이 나오는 경우이죠.\n",
        "\n",
        "전장유전체가 보편화 된 초기(2014년 쯤)에 `multi-allelic variant`는 큰 이슈였습니다. 그 시기쯤 GATK에서 joint genotyping module을 도입했고, multi-sample VCF가 만들어지기 시작했습니다. Multi-sample VCF를 만드는 joint genotyping은 하나의 샘플만 genotyping을 하는 individual genotyping보다 유리한 점이 많습니다.\n",
        "\n",
        "1. 각 variant에 대하여 샘플간의 유전형(genotype) 정보를 확보할 수 있습니다. 특히 reference homozygous genotype에 대한 정보와 그 genotype에 대한 품질지표를 확인할 수 있습니다.\n",
        "2. Variant calling에 포함된 샘플들의 품질지표를 사용하여 high quality variant를 정의하기 용이합니다.\n",
        "3. 가족 데이터를 사용할 경우 phasing이 용이합니다.\n",
        "\n",
        "자세한 정보는 아래 논문을 확인하세요 ([Zook et al. 2014](https://www.nature.com/articles/nbt.2835), [Koboldt 2020](https://genomemedicine.biomedcentral.com/articles/10.1186/s13073-020-00791-w)).\n",
        "\n",
        "Multi-sample VCF에서는 `ALT` 컬럼에 표시되는 allele이 두개 이상인 multi-allelic variant가 등장합니다. VCF에는 어떻게 표현이 되었는지 보시죠.\n",
        "\n",
        "```\n",
        "chr22\t50674782\t.\tC\tA,G\n",
        "\n",
        "```\n",
        "\n",
        "이 경우엔 일부 샘플은 `A` allele을 갖고 있고, 일부 샘플은 `G`를 갖고 있습니다. 두가지 variant가 등장을 했습니다. `C>A` 혹은 `C>G` 변이이지요. 만약 individual genotyping을 해서 하나의 샘플만 보았다면, 관찰되지 않을 경우입니다.\n",
        "\n",
        "혹은 이러한 경우도 존재합니다. `50675375`번째 위치를 보면 `[\"G\",\"*\",\"T\"]`라고 `* (STAR)`가 표시되어 있습니다. 이것은 alternative allele은 아닙니다. 이것은 같은 VCF에 있는 어떤 샘플이 deletion을 갖고 있는데, 그 지역에 다른 샘플이 SNV를 갖는 경우, 표시할 방법이 없기 때문에 위와 같이 표기를 합니다.\n",
        "\n",
        "Multi-allelic variant가 나오면, 각 variant에 대한 정보나 품질지표가 붙기 때문에 하나의 row에서 list나 array로 변환하기가 다소 번거롭습니다. 이러한 이유로 multi-allelic variant를 bi-allelic variant로 변형하는 작업이 필요합니다. Hail은 이 작업을 매우 간단하게 시행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82fa4f7e"
      },
      "outputs": [],
      "source": [
        "print(\"--> Before split variants with multi allele, the number of variants is :\", mt.rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aba6bad5"
      },
      "source": [
        "현재 우리 데이터는 총 16,515개의 variant가 존재합니다. 이제 `split_multi_hts()`라는 함수를 사용하여, multi-allelic variant를 분리(split)해봅시다.\n",
        "\n",
        "분리가 되고나면, 아래와 같이 변환이 됩니다.\n",
        "\n",
        "```\n",
        "chr22\t50674782\t.\tC\tA\n",
        "chr22\t50674782\t.\tC\tG\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "755e562e"
      },
      "outputs": [],
      "source": [
        "mt = hl.split_multi_hts(mt)\n",
        "mt = mt.checkpoint('data/out_test_chr22_split.mt')\n",
        "\n",
        "print(\"--> After split variants with multi allele, the number of variants is :\", mt.rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c6f7f47"
      },
      "source": [
        "Multi-allelic variant를 bi-allelic variant로 분리하고 나니, 총 17,898개의 변이로 변환됩니다.\n",
        "\n",
        "> 리빙포인트: 거의 모든 분석은 bi-allelic variant를 요구합니다. 따라서, `split_multi_hts()` 함수를 생활화 합시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41318cab"
      },
      "outputs": [],
      "source": [
        "# 이번에는 CRE 영역에서 발생한 변이들을 추출해봅시다\n",
        "mt.filter_rows(hl.is_defined(tb_encode_cre[mt.locus])).show()\n",
        "\n",
        "# 혹은 새로운 matrix table로 저장을 해봅시다\n",
        "mt_cre = mt.filter_rows(hl.is_defined(tb_encode_cre[mt.locus]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a23d373"
      },
      "source": [
        "이번에는 변이를 SNV(혹은 SNP)와 indel로 구분해봅시다.\n",
        "\n",
        "SNV는 염기의 숫자가 줄어들지 않고, 하나의 염기가 바뀌는 변이를 말하고, indel은 insertion과 deletion을 합친 약어로서 1개 이상 그리고 50개 미만의 염기서열이 변경되는 경우를 말합니다 (참고 여기서 몇개 미만에 대한 기준은 연구들마다 상이합니다).\n",
        "\n",
        "먼저 SNV의 숫자를 세어봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53808111",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"--> The number of SNVs is :\", mt.filter_rows(hl.is_snp(mt.alleles[0], mt.alleles[1])).count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a75b3a7"
      },
      "source": [
        "이번에는 indel의 숫자를 세어보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1a99bfc"
      },
      "outputs": [],
      "source": [
        "print(\"--> The number of Indel is :\", mt.filter_rows(hl.is_indel(mt.alleles[0], mt.alleles[1])).count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "407874bb"
      },
      "source": [
        "VCF 유전변이에 대한 정보나 품질지표가 `INFO` 컬럼에 포함되어 있습니다. 유전변이가 발생한 지점의 read depth (DP), strand bias (FS 혹은 SOR), mapping alignment quality (MQ) 등의 품질지표가 있고, locus에 있는 alternative allele의 숫자 (AC)나 확인된 allele의 숫자가 있습니다.\n",
        "\n",
        "먼저 Hail을 이용하여, `info`에 어떠한 지표들이 있는지 확인하고, 몇가지 지표들의 분포를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bef10b64"
      },
      "outputs": [],
      "source": [
        "mt.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e30bd7b"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.DP, title = 'DP')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6600d467"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.MQ, title = 'MQ')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1019e4d"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.SOR, title = 'SOR')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e092ec58"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.QD, title = 'QD')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fca4cc08"
      },
      "source": [
        "이번엔 AC와 AN의 정보를 확인해봅시다. AC와 AN은 전장유전체 정도관리 (quality control)에 매우 중요한 지표입니다. 여러명의 샘플을 joint genotyping 하는 경우에, 특정 부위는 variant calling이나 sequencing이 잘 안되는 경우가 발생합니다. 그러한 loci는 AN이 낮게 나타나고, 오직 소수의 샘플에서만 유전형이 확인됩니다. 이러한 변이는 연관성 검정에서 사용하기가 어렵습니다. 인간 유전체는 AN이 샘플수 * 2 (allele의 숫자)이 상염색체에선 최대값입니다.\n",
        "\n",
        "AC는 allele의 빈도를 구할때 중요한 지표입니다. VCF 상에서 AF를 정의하는 것은 AC/AN으로 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4374d57c"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.AC[0], title = 'AC') # AC는 array로 존재하므로, 첫번째 아이템을 선택합니다\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e2495b5"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.info.AN, title = 'AN')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4c6beb5"
      },
      "source": [
        "SNV와 Indel은 여러가지 이유로 품질지표에서 다른 분포를 갖습니다. 몇가지 지표를 보고 SNV와 indel의 차이점을 살펴봅시다. 먼저 SNV와 indel로 matrix table을 나누겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6f7753b"
      },
      "outputs": [],
      "source": [
        "mt_SNV = mt.filter_rows(hl.is_snp(mt.alleles[0], mt.alleles[1]))\n",
        "mt_Indel = mt.filter_rows(hl.is_indel(mt.alleles[0], mt.alleles[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e953709a"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt_SNV.info.MQ, title = 'MQ - SNV')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d0fde8f"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt_Indel.info.MQ, title = 'MQ - Indel')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5cb70a3"
      },
      "source": [
        "VCF에는 variant calling 알고리즘에 따라 분류된 quality filter가 존재합니다. 우리가 사용한 VCF는 GATK의 VQSR 모델에 따라 `PASS` filter를 제공합니다. 향후 분석을 위해 `PASS` variant만 사용하도록 추출합시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "621eeac8"
      },
      "outputs": [],
      "source": [
        "print(\"--> Before remove variants with VSQR pass failure, the number of variants is :\", mt.rows().count())\n",
        "mt = mt.filter_rows(hl.len(mt.filters) == 0)\n",
        "mt = mt.checkpoint('data/out_test_chr22_split_pass.mt')\n",
        "print(\"--> After remove variants with VSQR pass failure, the number of variants is :\", mt.rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e95c1fe"
      },
      "source": [
        "### 유전형 정보 확인하기\n",
        "\n",
        "유전변이(variant)와 다르게 유전형(genotype)은 개별 샘플에 나타나는 정보에 해당합니다.\n",
        "\n",
        "**1. Reference homozygous call**\n",
        "\n",
        "이에 속하는 샘플은 alternative allele이 없고 DNA 두쌍이 모두 reference allele을 갖습니다. 이런 경우를 `0/0`으로 표시합니다.\n",
        "\n",
        "**2. Heterozygous variant**\n",
        "\n",
        "이에 속하는 샘플은 DNA 두쌍 중 하나가 alternative allele을 갖고, 다른 하나는 reference allele을 갖습니다. 이런 경우를 `0/1`으로 표시합니다.\n",
        "\n",
        "**3. Homozygous variant**\n",
        "\n",
        "이에 속하는 샘플은 DNA 두쌍 중 하나가 alternative allele을 갖습니다. 이런 경우를 `1/1`으로 표시합니다.\n",
        "\n",
        "\n",
        "아래 FORMAT에 보면, `GT:AB:AD:DP:GQ:PL` 이라는 순서로 정보가 존재하고, 첫번째 샘플 (HG00096)은 `0/0:.:36,0:36:99:0,99,1301`을 갖습니다.\n",
        "\n",
        "\n",
        "```\n",
        "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tHG00096\tHG00097\tHG00099\n",
        "chr22\t50197100\t.\tT\tC\t13997.6\tPASS\tAC=24;AF=0.00374766;AN=6404;BaseQRankSum=0.364;ClippingRankSum=0.792;DP=121389;FS=2.436;MLEAC=24;MLEAF=0.003748;MQ=60;MQ0=0;MQRankSum=0.217;QD=13.17;ReadPosRankSum=0.892;SOR=0.862;VQSLOD=11.6;culprit=MQ;AN_EUR=1266;AN_EAS=1170;AN_AMR=980;AN_SAS=1202;AN_AFR=1786;AF_EUR=0;AF_EAS=0;AF_AMR=0.00408163;AF_SAS=0;AF_AFR=0.0111982;AC_EUR=0;AC_EAS=0;AC_AMR=4;AC_SAS=0;AC_AFR=20;AC_Het_EUR=0;AC_Het_EAS=0;AC_Het_AMR=4;AC_Het_SAS=0;AC_Het_AFR=20;AC_Het=24;AC_Hom_EUR=0;AC_Hom_EAS=0;AC_Hom_AMR=0;AC_Hom_SAS=0;AC_Hom_AFR=0;AC_Hom=0;HWE_EUR=1;ExcHet_EUR=1;HWE_EAS=1;ExcHet_EAS=1;HWE_AMR=1;ExcHet_AMR=0.993874;HWE_SAS=1;ExcHet_SAS=1;HWE_AFR=1;ExcHet_AFR=0.898023;HWE=1;ExcHet=0.957665;ME=0;AN_EUR_unrel=1006;AN_EAS_unrel=1008;AN_AMR_unrel=694;AN_SAS_unrel=978;AN_AFR_unrel=1322;AF_EUR_unrel=0;AF_EAS_unrel=0;AF_AMR_unrel=0.00288184;AF_SAS_unrel=0;AF_AFR_unrel=0.0121029;AC_EUR_unrel=0;AC_EAS_unrel=0;AC_AMR_unrel=2;AC_SAS_unrel=0;AC_AFR_unrel=16;AC_Het_EUR_unrel=0;AC_Het_EAS_unrel=0;AC_Het_AMR_unrel=2;AC_Het_SAS_unrel=0;AC_Het_AFR_unrel=16;AC_Hom_EUR_unrel=0;AC_Hom_EAS_unrel=0;AC_Hom_AMR_unrel=0;AC_Hom_SAS_unrel=0;AC_Hom_AFR_unrel=0;CSQ=C|upstream_gene_variant|MODIFIER|SELENOO|ENSG00000073169|Transcript|ENST00000380903|protein_coding|||||||||||3911|1||HGNC|HGNC:30395\tGT:AB:AD:DP:GQ:PL\t0/0:.:36,0:36:99:0,99,1301\t0/0:.:39,0:39:99:0,105,1260\t0/0:.:53,0:53:99:0,120,1800\n",
        "```\n",
        "\n",
        "AB는 allelic balance를 의미하고, reference allele과 alternative allele을 갖는 비율을 의미합니다. 즉 heterozygous variant이면, 50%의 비율로 AB가 형성되어야 합니다. AB는 VCF에 따라 homozygous 정보를 제공하지 않는 경우도 있습니다. 그래서 AD를 이용하여, AB를 계산합니다. AD는 array로 제공되는데, 첫번째 위치엔 reference allele를 갖는 read의 수, 두번째 위치엔 alternative allele를 갖는 read의 수가 존재합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16fc924d"
      },
      "outputs": [],
      "source": [
        "mt = mt.annotate_entries(AB = mt.AD[1] / hl.sum(mt.AD))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0960dc1f"
      },
      "source": [
        "이제 heterozygous variant의 AB를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b926331"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.filter_entries(mt.GT.is_het(), keep=True).AB, title = 'AB - heterozygous variant')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41ff0d1a"
      },
      "source": [
        "Heterozygous variant 임에도 불구하고, 50%에서 넓은 분포가 나타납니다. 여러가지 이유가 있습니다. 1) sequence read가 allele을 갖는것은 stochastic process임으로 확률적으로 분포를 갖습니다. 2) read 내에 존재하는 GC 염기서열의 분포에 따라 시퀀싱이나 PCR에 영향을 줍니다. 3) 현재 matrix table은 low quality variant를 포함하고 있고 이에 따라 낮은 AB가 나타나기도 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fea147d"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.filter_entries(mt.GT.is_hom_var(), keep=True).AB, title = 'AB - homozygous variant')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f136380a"
      },
      "source": [
        "Homozygous variant라고 예측된 변이들도 AB가 1보다 한참 떨어진 변이들이 관찰됩니다. 위에서 본 heterozygous variant와 동일한 이유입니다. 다시 말하자면, 우리가 전장유전체 분석을 하기 전에 high-quality variant 선별을 위해 상당히 꼼꼼하게 필터링을 수행해야합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a652c2b9"
      },
      "source": [
        "### 샘플 정보 확인하기\n",
        "\n",
        "우리는 위에 VCF를 matrix table로 불러들인후, 샘플 정보를 추가하였습니다. 추가된 정보를 먼저 확인해봅시다. `cols`에 저장된 정보를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421b91f9"
      },
      "outputs": [],
      "source": [
        "mt.cols().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a675240"
      },
      "source": [
        "먼저 가족별로 몇개의 샘플이 있는지를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0305112",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "mt.aggregate_cols(\n",
        "    hl.struct(n_families=hl.agg.counter(mt.fam))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e6ca3c2"
      },
      "source": [
        "일부는 3인가족으로 보이고, 일부는 그렇지 않습니다. 3인가족은 부모와 자녀를 의미합니다. 이러한 가족을 추출해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f26b464",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"Before filtering trios, (# of variants, # of samples) = \", mt.count())\n",
        "ID = hl.literal(mt.aggregate_cols(hl.agg.collect(mt.s)))\n",
        "fid = mt.filter_cols((ID.contains(mt.pat_id)) & (ID.contains(mt.mat_id))) # 부모의 ID가 모두 존재\n",
        "\n",
        "fid = hl.literal(fid.aggregate_cols(hl.agg.collect(fid.fam)))\n",
        "mt = mt.filter_cols(fid.contains(mt.fam))\n",
        "mt = mt.checkpoint('data/out_test_chr22_split_pass_trio.mt')\n",
        "\n",
        "print(\"After filtering trios, (# of variants, # of samples) = \", mt.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4f8be76"
      },
      "source": [
        "이제 trio 가족들만 남았습니다.\n",
        "\n",
        "이번에는 우리 데이터에 있는 여성 샘플의 비율을 계산해봅시다. Hail은 fraction을 직접 측정할 수도 있고, 아니면 직접 산출을 할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "739ecea9"
      },
      "outputs": [],
      "source": [
        "mt.aggregate_cols(\n",
        "    hl.struct(\n",
        "        fraction_female=hl.agg.fraction(mt.isFemale),\n",
        "        case_ratio=hl.agg.count_where(mt.isFemale) / hl.agg.count())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47d4a4c1"
      },
      "source": [
        "샘플에 저장된 continuous variable도 계산을 할 수 있습니다. 현재 튜토리얼 데이터에는 임의로 키(height)를 추가했습니다. 이를 활용하여 평균 값을 구해보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "487d8fdd"
      },
      "outputs": [],
      "source": [
        "mt.aggregate_cols(\n",
        "    hl.struct(\n",
        "        height_mean=hl.agg.mean(mt.height))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0301a93c"
      },
      "source": [
        "평균키는 167cm로 확인이 되었습니다.\n",
        "\n",
        "이번에는 키의 분포를 시각화해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb6b5eb1"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.height, title = 'Heights')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511e7e74"
      },
      "source": [
        "## 품질지표 확인 및 정도관리\n",
        "\n",
        "### 샘플\n",
        "\n",
        "전장유전체 분석을 하기 전에, 분석에 사용하는 모든 샘플이 균일하게 시퀀싱이 되었는지 확인할 필요가 있습니다. 먼저 각 샘플이 갖고 있는 변이에 관한 지표를 샘플별로 살펴보겠습니다. 많은 경우 SNV와 indel은 다른 품질 지표를 갖기 때문에, 둘을 구별하여 분석을 해보도록 하겠습니다.\n",
        "\n",
        "`sample_qc()` 라는 함수를 사용하면, 품질지표에 대한 정보를 계산해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1b93b56"
      },
      "outputs": [],
      "source": [
        "mt_SNV = hl.sample_qc(mt_SNV)\n",
        "mt_Indel = hl.sample_qc(mt_Indel)\n",
        "\n",
        "mt_SNV.cols().describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a62d01f9"
      },
      "source": [
        "`sample_qc`에 보면, DP, GQ, call_rate 등에 대한 여러가지 정보들이 제공되는 것을 볼 수 있습니다. 얻어진 정보는 `annotate_cols()` 함수를 이용하여, 원래 matrix table에 추가하도록 하겠습니다. 이후, `cols()`를 사용하여, 컬럼, 즉 샘플에 대한 정보만 matrix table로 추출합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06aa2996"
      },
      "outputs": [],
      "source": [
        "m_qc = mt.annotate_cols(n_non_ref_SNV = mt_SNV.cols()[mt.s].sample_qc.n_non_ref,\n",
        "                        n_non_ref_Indel = mt_Indel.cols()[mt.s].sample_qc.n_non_ref,\n",
        "                        r_ti_tv = mt_SNV.cols()[mt.s].sample_qc.r_ti_tv,\n",
        "                        dp_mean_SNV = mt_SNV.cols()[mt.s].sample_qc.dp_stats.mean,\n",
        "                        dp_mean_Indel = mt_Indel.cols()[mt.s].sample_qc.dp_stats.mean,\n",
        "                        gq_mean_SNV = mt_SNV.cols()[mt.s].sample_qc.gq_stats.mean,\n",
        "                        gq_mean_Indel = mt_Indel.cols()[mt.s].sample_qc.gq_stats.mean,\n",
        "                        call_rate_SNV = mt_SNV.cols()[mt.s].sample_qc.call_rate,\n",
        "                        call_rate_Indel = mt_Indel.cols()[mt.s].sample_qc.call_rate\n",
        "                     ).cols().key_by('s')\n",
        "\n",
        "m_qc.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8119df6"
      },
      "source": [
        "이제 샘플별로 나타난 SNV와 indel의 숫자를 확인해보도록 합시다. 아래 `non_ref`로 시작하는 것은 non-reference calls, 즉 variant를 의미하고, heterozygous variant와 alternative homozygous variant를 말합니다. SNV와 indel의 숫자를 확인하는건 전장유전체 데이터에서 가장 먼저 확인할 부분 중 하나입니다.\n",
        "\n",
        "> 리빙포인트: SNV와 indel의 분포가 군집을 이루는 것처럼 보인다면, 1) 주어진 데이터셋에 ancestry가 다른 샘플이 존재하거나, 2) 배치효과가 존재함을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b74aa48"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.scatter(x=m_qc.n_non_ref_SNV,\n",
        "                    y=m_qc.n_non_ref_Indel,\n",
        "                    xlabel='SNV',\n",
        "                    ylabel='Indel',\n",
        "                    hover_fields={'ID': m_qc.s},\n",
        "                    title = 'Number of variants',\n",
        "                    size=8)\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06d83908"
      },
      "source": [
        "몇가지 지표에 대한 플롯을 확인해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49845a23"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(m_qc['gq_mean_SNV'], legend='Mean Sample GQ - SNV')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cd9bb07"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(m_qc['gq_mean_Indel'], legend='Mean Sample GQ - Indel')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb7d92bb"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(m_qc['dp_mean_Indel'], legend='Mean Sample DP - Indel')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e102bdc"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(m_qc['call_rate_SNV'], legend='Call rate - SNV')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52704857-2456-455f-9654-bfaf96c52525"
      },
      "source": [
        "### 유전변이\n",
        "\n",
        "유전변이의 정도관리는 `variant_qc()` 함수를 통해 시행합니다. 샘플 수준의 정도관리인 `sample_qc()`와는 다른 기능입니다. `variant_qc()`는 하나의 variant (즉 row)에 대하여 모든 샘플에 나타나는 지표를 확인한 것이고, `sample_qc()`는 한 샘플에 대하여 모든 변이가 갖는 정보를 나타냅니다.\n",
        "\n",
        "`variant_qc()`를 한 후 추가된 정보에 대하여 시각화를 해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f904d741-c81b-4b66-b6f7-e166ac79635b"
      },
      "outputs": [],
      "source": [
        "mt = hl.variant_qc(mt)\n",
        "mt.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "799277f4"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.variant_qc.dp_stats['mean'], legend='Mean DP at the variant level')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcd38172"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.variant_qc['call_rate'], legend='Call rate of variants')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6149820"
      },
      "source": [
        "유전변이 수준에서 정도관리는 향후 downstream 분석에 매우 중요합니다. 분석에 쓰이는 변이가 품질의 차이에 의하여 연관성 분석에서 confounder로 작동하는 경우가 많습니다. 따라서 본인이 분석하고자 하는 전장유전체 데이터에서 어떤 품질지표가 있는지 면밀하게 확인할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d58efec"
      },
      "outputs": [],
      "source": [
        "mt.variant_qc.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43437243"
      },
      "outputs": [],
      "source": [
        "print(\"--> Before variant QC(call rate), the number of variants is :\", mt.rows().count())\n",
        "mt = mt.filter_rows((mt.variant_qc.call_rate >= 0.9))\n",
        "mt = mt.checkpoint('data/out_test_chr22_split_pass_trio_filtered1.mt', overwrite=True)\n",
        "print(\"--> After variant QC(call rate), the number of variants is :\", mt.rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dda834be"
      },
      "source": [
        "유전변이의 정도관리에 흔하게 적용하는 것 중에 하나는 low complexity region (LCR)에 발생하는 유전변이를 제거하는 것입니다. LCR은 bwa-mem을 개발한 Heng Li가 short read 시퀀싱에서 alignment가 잘 되지 않는 지점이라고 정의한 region입니다. 실제 여러분의 데이터에서 LCR 지역의 유전변이의 품질지표와 LCR 이외의 지역의 그것을 비교하면 상당한 차이가 발생합니다. 따라서 우리는 분석을 위해 LCR 지역의 변이를 제거하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e745bc7-f7a6-4c24-8611-d6807f8eac69"
      },
      "outputs": [],
      "source": [
        "print(\"--> Before remove variants in LCR, the number of variants is :\", mt.rows().count())\n",
        "lcr_bed = hl.import_bed(\"data/LCR-hs38.bed\", reference_genome = 'GRCh38')\n",
        "mt = mt.filter_rows(hl.is_defined(lcr_bed[mt.locus]), keep=False)\n",
        "mt = mt.checkpoint('data/out_test_chr22_split_pass_trio_filtered2.mt')\n",
        "print(\"--> After remove variants in LCR, the number of variants is :\", mt.rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da25be3b-adc2-4f1d-96b4-02597cbf7b2e"
      },
      "source": [
        "### 유전형"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4b4240"
      },
      "source": [
        "유전형 정보는 샘플 당 고유하게 존재합니다. 우리는 유전형 정보를 바탕으로 기대했던 population structure이 존재하는지 확인하고자 합니다. 만약 다른 패턴이 나오면, 유전형에 영향을 주는 어떤 이유를 생각해볼 수 있습니다. 우선 PCA를 시행해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c10ca157"
      },
      "outputs": [],
      "source": [
        "eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT, k=2) # 시간 절약을 위해 k는 2로 설정합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b660866"
      },
      "outputs": [],
      "source": [
        "mt = mt.annotate_cols(scores = pcs[mt.s].scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "009d265b"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.scatter(mt.scores[0],\n",
        "                    mt.scores[1],\n",
        "                    label=mt.population,\n",
        "                    title='PCA', xlabel='PC1', ylabel='PC2')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f07369e9-d44b-4e72-8bf5-1182dcf45f98"
      },
      "source": [
        "## Variant Annotation 와 Classification 하기\n",
        "\n",
        "VCF 데이터는 유전변이 정보를 담고 있지만, 각 유전변이가 어떠한 유전자/단백질을 변화시키는지, 기능적으로 의미가 있을지 등등에 대한 정보를 제공하지 않습니다. 그래서 유전변이의 위치와 서열에 따라 위 정보들을 추가하는 과정이 필요합니다. 우리는 이 과정을 variant annotation이라 부릅니다. 우리말로 굳이 번역을 하면 '주석화'라고 하는데, 의미가 직접적으로 전달되진 않습니다.\n",
        "\n",
        "Variant annotation은 유전변이 분석에서 매우 중요한 부분을 차지합니다. 변이의 기능성을 판별하는 과정이면서 동시에 annotation에 사용되는 다양한 방법과 참조 유전체 데이터 및 리소스에 따라 결과가 조금씩 다르게 나옵니다. 그래서 어떠한 방법으로 annotation을 했는지 기준을 세우고 정확히 명시할 필요가 있습니다.\n",
        "\n",
        "우리는 튜토리얼에서 Ensembl Variant Effect Predictor(VEP)를 이용한 variant annotation을 하려고 합니다. Hail에서는 matrix table에 직접 VEP를 할 수 있게 아래와 같이 `vep()`라는 함수를 제공합니다.\n",
        "\n",
        "```\n",
        "mt_vep = hl.vep(mt, \"path/to/vep-configuration.json\")\n",
        "```\n",
        "\n",
        "VEP가 설치된 path와 annotation 파라미터를 json 파일로 저장하고, `vep()` 함수에 넣어주면 됩니다. 하지만 이렇게 hail 내에서 VEP annotation을 하려면 상당히 많은 리소스가 필요하기 때문에, 튜토리얼에서 진행하긴 어렵기 때문에, 제가 커맨드라인으로 미리 VEP를 했고, 처음 불러들인 VCF에 VEP annotation이 포함되어 있습니다.\n",
        "\n",
        "```\n",
        "# 터미널에서 VEP 구동하기\n",
        "./vep -i $in.vcf -o $out.vcf --vcf \\\n",
        "  --per_gene --pick --pick_order canonical,appris,tsl,biotype,ccds,rank,length --cache\n",
        "```\n",
        "\n",
        "우리는 이번 튜토리얼에선 이 데이터를 사용하지만, 보통은 hail 내의 `vep()` 함수를 사용하길 추천합니다.\n",
        "\n",
        "\n",
        "> 한가지 꼭 기억을 해야할 것은 variant annotation 방식은 전장유전체를 포함한 유전체 연구별로 상당히 상이합니다. 향후 분석 (특히 대규모 분석)에서 연구 재현성을 확보하기 위해선, variant annotation 코드와 scheme을 정확히 명시할 필요가 있습니다. 아마 많은 연구자들이 VEP 말고 ANNOVAR, SNPEFF 등을 많이 사용할겁니다. 이런 툴들도 상당히 좋습니다만, 요즘 이뤄지는 대규모 연구들은 VEP를 기반으로 annotation을 합니다. 각 툴은 고유의 annotation scheme이 있기 때문에 (예를들어, coding variant에서 어떤 순서로 consequence를 주는가? 등등), ANNOVAR의 결과와 VEP의 결과가 정확히 일치하지 않을수 있습니다. 이후 downstream 분석들 (연관성 분석 등등)에서 다른 결과를 줄수 있죠. 그래서 가능한 널리 통용되는 툴을 사용할 필요가 있고, 개인적인 추천은 VEP 입니다.\n",
        "\n",
        "\n",
        "    \n",
        "### VEP와 variant annotation\n",
        "\n",
        "VEP를 이용한 variant annotation은 다음과 같은 기능을 제공합니다.\n",
        "\n",
        "- 유전변이의 결과값(consequence): stop codon, nonsynonymous, UTR, upstream (promoter), intron, intergenic\n",
        "- 유전변이의 기능적 수치(functional score): SIFT, PolyPhen2, CADD 등등\n",
        "- 유전변이의 기능적 정보들: epigenome, transcriptome 데이터 등등\n",
        "\n",
        "다양한 기능적 정보들을 plugin을 통해 제공하고 유저는 자유롭게 추가할 수 있습니다.\n",
        "\n",
        "\n",
        "우리는 input VCF에 VEP를 미리 해두었기 때문에, 이에 대한 정보가 VCF header에 기록되어 있습니다. VEP는 consequence 정보를 `CSQ`라는 tag으로 기록하고, 정보들을 `|`으로 구분하여 제공합니다. 이 정보는 각 variant (row)에 동일한 순서로 제공합니다.\n",
        "\n",
        "이제 `get_vcf_metadata()` 함수를 이용하여, CSQ에 어떤 정보가 기록되었는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57b78546-bc62-465f-bf02-9479559a9f04"
      },
      "outputs": [],
      "source": [
        "h = hl.get_vcf_metadata('data/out.test.chr22.vcf.bgz')\n",
        "h['info']['CSQ']['Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f11892e"
      },
      "source": [
        "위에서 확인한 바와 같이 정보들은 array의 형태로 제공이 됩니다. 우리는 이 정보를 matrix table에 `CSQ` 필드에 저장하여 이후 분석에 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de6b295f"
      },
      "outputs": [],
      "source": [
        "mt = mt.annotate_rows(CSQ = hl.struct(\n",
        "    Allele=mt.info.CSQ[0].split('\\|')[0],\n",
        "    Consequence=mt.info.CSQ[0].split('\\|')[1],\n",
        "    IMPACT=mt.info.CSQ[0].split('\\|')[2],\n",
        "    SYMBOL=mt.info.CSQ[0].split('\\|')[3],\n",
        "    Gene=mt.info.CSQ[0].split('\\|')[4],\n",
        "    DISTANCE=hl.int64(mt.info.CSQ[0].split('\\|')[18]))\n",
        ")\n",
        "mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9dcf233"
      },
      "source": [
        "이제 총 몇개의 consequence가 발생했는지 확인해봅시다. `counter()` 함수를 사용하여 계수를 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61e82234"
      },
      "outputs": [],
      "source": [
        "d = mt.aggregate_rows(hl.agg.counter(mt.CSQ.Consequence))\n",
        "pd.DataFrame.from_dict(d, orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcc7bf4"
      },
      "source": [
        "예상했던대로 noncoding genome에 변이들(intronic, integenic, upstream/downstream)에 많이 발생하는 것을 볼수 있습니다.\n",
        "\n",
        "이번에는 유전변이가 발생하는 위치에 따라 변이의 빈도수가 어떻게 달라지는지 한번 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba3556c0"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.filter_rows(mt.CSQ.Consequence=='intergenic_variant').info.AC[0],\n",
        "                      title = 'Allele counts of intergenic variants')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59c1f111"
      },
      "outputs": [],
      "source": [
        "p = hl.plot.histogram(mt.filter_rows(mt.CSQ.Consequence=='missense_variant').info.AC[0],\n",
        "                      title = 'Allele counts of missense variants')\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ca62af5"
      },
      "source": [
        "Intergenic variant가 missense variant보다 high AC variant가 많은 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ae70d16-559e-46ff-a001-880e6522ad6d"
      },
      "source": [
        "### 커스텀 데이터 사용\n",
        "\n",
        "Variant annotation은 실험에 따라 다양한 외부 데이터를 추가할 수 있습니다. 이번에는 hail table로 저장된 annotation 데이터를 추가해보겠습니다. 아래는 missense variant의 위험도를 측정하기 위해 [MPC (missense badness, PolyPhen-2, and constraint) score](https://www.biorxiv.org/content/10.1101/148353v1)를 사용해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a8ac29c"
      },
      "outputs": [],
      "source": [
        "MPC = hl.read_table(\"data/MPC_chr22.ht\")\n",
        "MPC.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f25728ce"
      },
      "outputs": [],
      "source": [
        "MPC = MPC.key_by(\"locus\", \"alleles\")\n",
        "mt = mt.key_rows_by(mt.locus, mt.alleles)\n",
        "mt = mt.annotate_rows(MPC = MPC[mt.locus, mt.alleles].MPC) # locus와 allele을 기준으로 두 matrix table을 연결합니다\n",
        "print(\"--> The number of variants with MPC ≥ 2 is :\", mt.filter_rows(mt.MPC >= 2).rows().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11c8dd74"
      },
      "source": [
        "MPC score가 잘 annotate 된 것으로 확인됩니다. MPC가 2이상인 변이를 선별해보니 총 3개가 존재합니다.\n",
        "\n",
        "이번에는 allele frequency (AF)에 대한 public database를 사용하여, annotation을 해봅시다. 현재 VCF에는 1000 Genome Project 팀에서 미리 만들어둔 AF 정보가 존재하지만, 튜토리얼을 위해 없다고 가정하고 진행해보겠습니다. 가장 널리 사용되는 AF 데이터는 [gnomAD](https://gnomad.broadinstitute.org/)입니다. 우리는 튜토리얼을 위해, [한국인 전장유전체](https://www.science.org/doi/10.1126/sciadv.aaz7835)과 [일본인 전장유전체](https://togovar.biosciencedbc.jp) 연구에서 얻은 AF를 포함한 AF를 `AF` 컬럼에 저장했고, 이 정보를 사용하도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6762c4f-0a14-465d-bb43-3119e02208ca",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "AF_table = hl.read_table('data/gnomadv3_1_non_neuro_adj_chr22.ht')\n",
        "AF_table.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cb98883"
      },
      "source": [
        "위와 마찬가지로 locus와 allele을 사용하여 AF 정보를 추가하고자 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e33dba8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "AF_table = AF_table.key_by(\"locus\", \"alleles\")\n",
        "mt = mt.annotate_rows(public_AF = AF_table[mt.locus, mt.alleles])\n",
        "# mt = mt.key_rows_by(mt.locus, mt.alleles)\n",
        "mt.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b661a051"
      },
      "outputs": [],
      "source": [
        "mt.public_AF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65fbbf89-0066-499f-aeef-70370c8b4f24"
      },
      "source": [
        "## Qualifying variant 추출하기\n",
        "\n",
        "우리가 유전변이 연관성 분석을 할때, input으로 들어가는 변이를 qualifying variant (QV)라고 부릅니다. 각 연구에서 검정하고자 하는 가설에 따라 원하는 유전변이가 다릅니다. Common variant를 분석하려면, AF를 선정하거나 LD를 고려하여 변이를 선별해야합니다. Rare recessive variant를 분석하고자 한다면, genotype에서 homozygous variant를 선별하고, 특정 인구집단에서 AF가 몇 퍼센트 이하인 기준을 세워서 필터링을 합니다. 이렇게 각 목적마다 주어지는 input이 다르고, 이를 정의하여 추출한 변이를 QV라고 부릅니다. 또한 위에서 본 것과 같이 많은 false positive를 적절하게 제어하기 위해서도 필터링 단계는 매우 중요합니다.\n",
        "\n",
        "이번 섹션에서는 위에서 연습한 내용을 종합하여, 목적에 맞는 QV를 선별해봅시다.\n",
        "\n",
        "\n",
        "\n",
        "### 신규변이 (de novo variant)\n",
        "\n",
        "De novo variant (DNV)는 발달성 질환에 가장 주된 원인으로 지난 10년간 NGS연구에서 암의 somatic mutation과 함께 가장 널리 연구된 주제입니다. DNV를 추출하는 여러가지 알고리즘이 있지만, VCF를 외부 프로그램 사용을 위해 변환하고 다시 수집하는 과정은 코드의 재현성이나 tidy함을 확보하기 굉장히 어렵습니다. 그래서 Hail은 DNV 탐색 알고리즘을 제공하고 있습니다. 우리는 대규모 자폐증 전장유전체 연구([An et al. 2018, Science](https://www.science.org/doi/10.1126/science.aat6576))의 필터링 기준을 따라 DNV를 추출해보고자 합니다.\n",
        "\n",
        "* 선별 기준\n",
        "     - AF ≤ 0.001 (0.1%)\n",
        "     - Filtering high quality de novo variants using quality metrics(AB, DP, GQ)\n",
        "     - DNV test high/medium confidence\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c772f15-ff04-4996-9c6d-9faddeafa19e"
      },
      "outputs": [],
      "source": [
        "DNV = mt.filter_rows(mt.public_AF.AF <= 0.001) # 0.1%\n",
        "DNV.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57b01b70-1410-45b6-997a-acdf4e47053e"
      },
      "outputs": [],
      "source": [
        "trio_fam = hl.Pedigree.read('data/1kg_v3_20200731_complete_fam_633.ped')\n",
        "dnv_test = hl.de_novo(mt=DNV,\n",
        "                        pedigree=trio_fam,\n",
        "                        pop_frequency_prior=DNV.public_AF.AF,\n",
        "                        max_parent_ab= 0.05,\n",
        "                        min_child_ab = 0.2,\n",
        "                        min_dp_ratio = 0.1,\n",
        "                        min_gq=20)\n",
        "print(\"--> De novo variants from complete trio(n_proband+control = 596) : \", dnv_test.aggregate(hl.agg.counter(dnv_test.confidence)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7f6544b-67e4-47e9-9a63-4cde0a72874d"
      },
      "outputs": [],
      "source": [
        "DNV = dnv_test.filter((dnv_test.confidence==\"HIGH\") | (dnv_test.confidence==\"MEDIUM\"))\n",
        "DNV.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27018585-b39b-4608-babe-b466ed3de62b"
      },
      "source": [
        "### 희귀변이 (Rare Variants)\n",
        "\n",
        "희귀변이는 집단에 AF가 낮게 존재하는 변이를 말합니다. 전장유전체 코호트가 커질수록 질환이나 형질에 영향을 보다 큰 영향을 미칠 것이라 생각하는 희귀변이 연구들이 많이 진행되고 있습니다. 희귀변이는 공통변이(common variant)와 다르게 품질지표나 AF 데이터베이스에 따른 분포가 상이하기 때문에 QV를 추출할때 보다 정확하게 진행을 해야합니다. 우리는 대규모 유전체 연구([Satterstrom et al. 2020 Cell](https://www.cell.com/cell/fulltext/S0092-8674(19)31398-4), [Werling et al. 2018 Nature Genetics](https://www.nature.com/articles/s41588-018-0107-y))에서 시행된 추출 방법에 따라 heterozygous와 homozygous variant를 추출해보고자 합니다.\n",
        "\n",
        "#### Rare heterozygous variant\n",
        "\n",
        "\n",
        "* 선별 기준\n",
        "     - AF ≤ 0.001, AC ≤ 5\n",
        "     - Filtering high quality heterozygous variants using quality metrics(GQ, AB, VQSLOD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f86e1a7-c69a-4739-93ea-01f352efa81e"
      },
      "outputs": [],
      "source": [
        "filter_condition_entry = ((mt.GT.is_het()) & (mt.GQ >= 25) & (mt.AB >= 0.3))\n",
        "RareHet = mt.filter_entries(filter_condition_entry)\n",
        "print(\"--> After remove variants with low quality(based on GQ, AB), the number of het entries is :\", RareHet.entries().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afe5405d-25b9-4901-ad7d-e147e3b47110"
      },
      "outputs": [],
      "source": [
        "filter_condition_variant = (((hl.is_snp(RareHet.alleles[0], RareHet.alleles[1])) & (RareHet.info.VQSLOD >= -2.085))|\n",
        "                            (~hl.is_snp(RareHet.alleles[0], RareHet.alleles[1])))\n",
        "RareHet = RareHet.filter_rows(filter_condition_variant)\n",
        "print(\"--> After remove SNVs with VQSLOD<-2.085, the number of variants is reduced to :\", RareHet.rows().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d109cdd7-2637-4711-8a8b-4e2ed4a3a5c0"
      },
      "outputs": [],
      "source": [
        "RareHet = RareHet.filter_rows((RareHet.public_AF.AF<=0.001) & (RareHet.info.AC[0]<=5))\n",
        "RareHet.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca15d0ed-27b2-460a-a035-81c769fb05bb"
      },
      "outputs": [],
      "source": [
        "RareHet = RareHet.filter_cols(hl.is_defined(RareHet.ROLE)) # 자녀에게 있는 heterozygous만 선별\n",
        "RareHet = RareHet.entries()\n",
        "print(\"--> In 596 children, there are \", RareHet.count(), \" high quality rare het mutations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "527c1c43-c2c9-4bcf-ab07-133fcbfa9737"
      },
      "source": [
        "#### Rare Homozygous variant\n",
        "\n",
        "Homozygous variant는 genotype을 갖고 필터링을 합니다. 더 복잡한 상황을 가정해보죠. 부모에게는 heterozygous variant이고, 자녀에게는 homozygous variant로 나오는 경우들을 추출해봅시다.\n",
        "\n",
        "* 선별기준\n",
        "     - Filtering homozygous variants where genotype of both parents are heterozygous\n",
        "     - Filtering high quality homozygous variants using quality metrics(GQ, AB, DP, AN, QD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "006d5d3b-d3d2-4d63-8030-4bcd79c8046d"
      },
      "outputs": [],
      "source": [
        "RareHom = mt.filter_entries(mt.GT.is_non_ref())\n",
        "RareHom = RareHom.filter_rows(RareHom.public_AF.AF <= 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aadc934-cf55-471c-97b3-9242f63c75a9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tb = RareHom.key_cols_by().entries()\n",
        "rare_hom = tb.filter((hl.is_missing(tb.ROLE)) & (tb.GT.is_het_ref()))\n",
        "rare_hom_tag = rare_hom.group_by(rare_hom.locus, rare_hom.alleles, rare_hom.fam).aggregate(nHet = hl.agg.collect(rare_hom.ROLE))\n",
        "rare_hom_tag = rare_hom_tag.annotate(nHet = hl.len(rare_hom_tag.nHet))\n",
        "rare_hom_tag = rare_hom_tag.filter(rare_hom_tag.nHet == 2)\n",
        "tb = tb.key_by('locus', 'alleles', 'fam').semi_join(rare_hom_tag)\n",
        "print(\"--> After variant filtering families with het parents, the number of variants is :\", tb.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d2a70f6-f031-4660-8d41-621ecefe690e"
      },
      "outputs": [],
      "source": [
        "filter_condition = ((tb.GT.is_hom_var()) & (tb.GQ >= 30) & (tb.AB >= 0.95) & (tb.DP >= 18))\n",
        "tb = tb.filter(filter_condition)\n",
        "print(\"--> After remove variants with low quality(based on GQ, AB, DP), the number of hom entries is :\", tb.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bd3e1a5-b2c2-4f05-9ba8-95feb392d7dc"
      },
      "outputs": [],
      "source": [
        "# 자녀에게 나오는 변이만 추출\n",
        "tb = tb.filter(hl.is_defined(tb.ROLE))\n",
        "RareHom = tb.key_by('locus', 'alleles', 's')\n",
        "print(\"--> In 596 children, there are \", tb.count(), \" high quality rare hom mutations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a0e3dd"
      },
      "source": [
        "## Association testing\n",
        "\n",
        "Hail을 이용하여서 [GWAS](https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#GWAS-Tutorial), [SKAT](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.skat) 등의 다양한 연관성 방법을 사용할 수 있습니다. 추가 튜토리얼은 위 링크를 참고하길 바랍니다.\n",
        "\n",
        "### Linear regression\n",
        "\n",
        "Hail을 이용하여 간단한 regression 검정을 해봅시다. Sample 정보에 있는 임의의 정보를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38678e4e"
      },
      "outputs": [],
      "source": [
        "result_ht = hl.linear_regression_rows(y=mt.height,\n",
        "                                x=mt.GT.n_alt_alleles(),\n",
        "                                covariates=[1, mt.isFemale, mt.scores[0], mt.scores[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0eb6bfa"
      },
      "outputs": [],
      "source": [
        "result_ht.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hail",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}